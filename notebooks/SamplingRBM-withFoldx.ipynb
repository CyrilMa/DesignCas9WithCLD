{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3b050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:45:22.499421Z",
     "start_time": "2023-01-24T18:45:13.385083Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re, random, warnings, subprocess, time\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import * \n",
    "\n",
    "from itertools import product\n",
    "from random import shuffle\n",
    "\n",
    "import torch, torch_geometric\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchpgm.model import *\n",
    "from torchpgm.layers import *\n",
    "\n",
    "from cld.postprocessing import *\n",
    "from cld.criterion import *\n",
    "from cld.walker import *\n",
    "\n",
    "from utils import *\n",
    "from config import *\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import *\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d974b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:45:22.505276Z",
     "start_time": "2023-01-24T18:45:22.501081Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "folder = f\"{DATA}/vink\"\n",
    "Nh, Npam = 200, 5\n",
    "best_epoch = 90\n",
    "q_pi, N_pi = 21, 736\n",
    "model_full_name = f\"rbmssl2_pid_h{Nh}_npam{Npam}_gamma1\"\n",
    "\n",
    "def lit_to_pam(s):\n",
    "    pam = []\n",
    "    s += \"N\" * max(0, (Npam - len(s)))\n",
    "    for x in s:\n",
    "        pam += NAd_idx[x]\n",
    "    return torch.tensor(pam).float()[None].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ec797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:45:32.426102Z",
     "start_time": "2023-01-24T18:45:22.506317Z"
    }
   },
   "outputs": [],
   "source": [
    "pi = OneHotLayer(None, N=N_pi, q=q_pi, name=\"pi\")\n",
    "h = GaussianLayer(N=Nh, name=\"hidden\")\n",
    "classifier = PAM_classifier(Nh, Npam * 4)\n",
    "E = [(pi.name, h.name)]\n",
    "E.sort()\n",
    "\n",
    "model_rbm = PI_RBM_SSL(classifier, layers={pi.name: pi, h.name: h}, edges=E, name=model_full_name)\n",
    "model_rbm = model_rbm.to(device)\n",
    "model_rbm.load(f\"{folder}/weights/{model_full_name}_{best_epoch}.h5\")\n",
    "model_rbm.eval()\n",
    "model_rbm = model_rbm.to(\"cpu\")\n",
    "model_rbm.ais()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2cc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:45:32.432346Z",
     "start_time": "2023-01-24T18:45:32.428294Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cas9 = torch.load(f\"{DATA}/x_cas9.pt\")\n",
    "zero_idx = torch.load(f\"{DATA}/zero_idx.pt\")\n",
    "kept_idx = list(range(736))\n",
    "target = lit_to_pam(\"NGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004327a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:46:49.170574Z",
     "start_time": "2023-01-24T18:45:32.433843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "e_plage = [(e0-0.03, e0-0.02)]    \n",
    "sim_plage = [(30, 35),(50, 55)]\n",
    "x = []\n",
    "TRACKS = []\n",
    "for s, e in product(sim_plage,e_plage):\n",
    "    T = 0.1*torch.ones(1,1,len(kept_idx))\n",
    "    objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "    constraints = [\n",
    "                SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "    ]\n",
    "    weight_constraints = [10,1000]\n",
    "\n",
    "    walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=1, n=1, a=1,\n",
    "            c=1e-2, eps=1, target=target.cpu(), T=T, weight_constraints = weight_constraints)\n",
    "\n",
    "    x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "    e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "    for e_ in e.T[:10]:\n",
    "        plt.plot(e_)\n",
    "    plt.show()\n",
    "    sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "    for sim_ in sim.T[:10]:\n",
    "        plt.plot(sim_)\n",
    "    plt.show()\n",
    "    TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e2d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T18:48:07.572614Z",
     "start_time": "2023-01-24T18:48:04.785978Z"
    }
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "for (track_e, track_s), (s, e) in zip(TRACKS,product(sim_plage,e_plage)):\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.subplot(121)\n",
    "    print(e,s)\n",
    "    for e_ in track_e[:5]:\n",
    "        plt.plot(gaussian_filter1d(-e_,n,  mode=\"nearest\"))\n",
    "    plt.plot([0,100],[.15,-e[0]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[0],-e[0]],color=\"black\")\n",
    "    plt.plot([0,100],[.15,-e[1]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[1],-e[1]],color=\"black\")\n",
    "    plt.ylabel(\"E_RBM\")\n",
    "    plt.xlabel(\"Langevin Dynamic Step\")\n",
    "\n",
    "    #plt.show()\n",
    "    plt.subplot(122)\n",
    "    for sim_ in track_s[:5]:\n",
    "        plt.plot(gaussian_filter1d(sim_,n,  mode=\"nearest\"))\n",
    "    plt.plot([0,100],[0,s[0]],color=\"black\")\n",
    "    plt.plot([100,200],[s[0],s[0]],color=\"black\")\n",
    "    plt.plot([0,100],[0,s[1]],color=\"black\")\n",
    "    plt.plot([100,200],[s[1],s[1]],color=\"black\")\n",
    "    \n",
    "    plt.ylabel(\"Distance to SpyCas9\")\n",
    "    plt.xlabel(\"Langevin Dynamic Step\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdfc5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T16:59:50.224666Z",
     "start_time": "2023-01-19T16:59:50.184995Z"
    },
    "code_folding": [
     23,
     42,
     54,
     73,
     83,
     104,
     116,
     122,
     128,
     132,
     139
    ]
   },
   "outputs": [],
   "source": [
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pyfoldx as foldx\n",
    "from pyfoldx.structure import Structure\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical\n",
    "NAd_in = {\"A\":\"A\", \"T\":\"T\", \"C\":\"C\", \"G\":\"G\",\n",
    "          \"W\":\"AT\", \"S\":\"CG\", \"M\":\"AC\", \"K\":\"TG\", \"R\":\"AG\", \"Y\":\"TC\",\n",
    "           \"B\":\"TCG\", \"D\":\"ATG\", \"H\":\"ATC\", \"V\": \"ACG\", \"N\":\"ATCG\"}\n",
    "NAd = [\"O\",\"A\",\"T\",\"W\",\"C\",\"M\",\"Y\",\"H\",\"G\",\"R\",\"K\",\"D\",\"S\",\"V\",\"B\",\"N\"]\n",
    "\n",
    "pl3to1 = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "pl1to3 = {v:k for k,v in pl3to1.items()}\n",
    "\n",
    "device = \"cpu\"\n",
    "def aux(args):\n",
    "    seq, struct, repair = args\n",
    "    chain = \"A\"\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1102\n",
    "    for target in seq[:]:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    #s_new.repair()\n",
    "    return float(s_new.getTotalEnergy().loc[\"model\"][\"total\"])\n",
    "\n",
    "def foldx_energy(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        energies = pool.map(aux, list(zip(seqs, structs, repairs,)))\n",
    "        \n",
    "    #energies = [aux(seq, struct, repair) for seq, struct, repair in zip(seqs, structs, repairs)]\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def aux_with_dna(args):\n",
    "    seq, struct, repair, = args\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1102\n",
    "    chain = \"A\"\n",
    "    for target in seq:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    #s_new.repair()\n",
    "    return float(s_new.getTotalEnergy().loc[\"model\"][\"total\"])\n",
    "\n",
    "def foldx_energy_with_dna(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        energies = pool.map(aux_with_dna, list(zip(seqs, structs, repairs,)))\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def aux_with_dna_interface(args):\n",
    "    seq, struct, repair, = args\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1\n",
    "    chain = \"A\"\n",
    "    for target in seq[:]:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    if do_repair:\n",
    "        #s_new.repair()\n",
    "        structures[idx] = deepcopy(s_new)\n",
    "    return float(s_new.getInterfaceEnergy(verbose=False)[\"Interaction Energy\"].loc[\"B\"].loc[\"D\"])\n",
    "\n",
    "def interface_energy_with_dna(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        structs = [deepcopy(s) for s in structs]\n",
    "        energies = pool.map(aux_with_dna_interface, list(zip(seqs, structs, repairs,)))\n",
    "    #energies = [aux(seq, struct, repair) for seq, struct, repair in zip(seqs, structs, repairs)]\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def abs_diff(x, x0):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    x0 = x0.reshape(x0.size(0),21,-1)\n",
    "\n",
    "    return (x[:,:,nnz_idx].argmax(1) != x0[:,:,nnz_idx].argmax(1)).int().float().sum(-1)\n",
    "\n",
    "def mean_diff(x, x0):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    x0 = x0.reshape(x0.size(0),21,-1)\n",
    "\n",
    "    return (x[:,:,nnz_idx].argmax(1) != x0[:,:,nnz_idx].argmax(1)).int().float().mean(-1)\n",
    "\n",
    "def isd(x):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    return (x[:,0,nnz_idx].mean(-1)) + (1-(x[:,0,zero_idx].mean(-1)))\n",
    "\n",
    "def litpam_to_pam(s):\n",
    "    pam = []\n",
    "    s += \"N\"*max(0,(Npam-len(s)))\n",
    "    for x in s:\n",
    "        pam += NAd_idx[x]\n",
    "    return torch.tensor(pam).float()[None].to(device)\n",
    "\n",
    "def find_closest_sequence(x):\n",
    "    x = x.view(len(x), 21, -1)\n",
    "    distance = (x[:,:,:].argmax(-2)[:,None] != existing_sequences[:,:,:].argmax(-2)[None]).int().sum(-1).min(1)[0]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a05c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T17:01:31.921455Z",
     "start_time": "2023-01-19T17:01:31.916236Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(x_cas9, f\"{DATA}/x_cas9.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c1a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T14:05:57.558067Z",
     "start_time": "2022-12-22T14:05:57.547602Z"
    }
   },
   "outputs": [],
   "source": [
    "gammas = gammas = [1]+[2*1.05**i for i in range(50)]+[0]+[1e-7*1.05**i for i in range(100)]+[1.4**i/1000 for i in range(50)]+[0.01*1.05**i for i in range(150)]+[0.0001*1.05**i for i in range(100)]+[1e-5*1.05**i for i in range(50)]+[10000*1.1**i for i in range(50)]+[20*1.08**i for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0649f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "constraints = [\n",
    "    SimCriterion(x_cas9, nnz_idx, postprocessing=ConstantPostprocessor(None, 80)),\n",
    "    RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(-0.5, None)),\n",
    "]\n",
    "\n",
    "T = 0.3 * torch.ones(1, 1, len(kept_idx))\n",
    "\n",
    "walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=1, n=1, a=1,\n",
    "                c=1e-2, eps=1, target=target.cpu(), T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57a2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:25:58.828480Z",
     "start_time": "2023-01-20T18:25:58.817786Z"
    }
   },
   "outputs": [],
   "source": [
    "gammas = gammas = [1]+[2*1.05**i for i in range(50)]+[0]+[1e-7*1.05**i for i in range(100)]+[1.4**i/1000 for i in range(50)]+[0.01*1.05**i for i in range(150)]+[0.0001*1.05**i for i in range(100)]+[1e-5*1.05**i for i in range(50)]+[10000*1.1**i for i in range(50)]+[20*1.08**i for i in range(50)]\n",
    "selected_gammas = sorted(gammas)[260:542]\n",
    "sim_plage = [(5*i,5*i+5) for i in range(2,10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81beab9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-14T15:14:48.003Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "folder = \"/home/malbranke/data/cas9/vink\"\n",
    "for gamma in selected_gammas:\n",
    "    x = []\n",
    "    TRACKS = []\n",
    "    model_full_name = f\"rbmssl2_pid_h{Nh}_npam{Npam}_gamma{gamma}\"\n",
    "\n",
    "    model_rbm = PI_RBM_SSL(classifier, layers= {pi.name: pi, h.name: h}, edges=E, name = model_full_name)\n",
    "    model_rbm = model_rbm.to(device)\n",
    "    model_rbm.load(f\"{folder}/weights/{model_full_name}_{best_epoch}.h5\")\n",
    "    model_rbm.eval()\n",
    "    model_rbm.ais()\n",
    "    model_rbm = model_rbm.to(\"cpu\")\n",
    "    \n",
    "    idx0 = 0\n",
    "    idx = (idx0*torch.ones(512).int()).to(device)\n",
    "\n",
    "    criterion = classifier_criterion(classifier, edge, target)\n",
    "    x__ = torch.cat([X_rbm[0][None] for i in idx],0)\n",
    "\n",
    "    x_cas9 = torch.clone(x__[0].view(-1))\n",
    "    h_cas9 = edge(x_cas9[None], False)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "    e_plage = [(e0-0.02, e0+0.02)]\n",
    "\n",
    "    for s, e in product(sim_plage,e_plage):\n",
    "        T = 0.1*torch.ones(1,1,len(kept_idx))\n",
    "        objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "        constraints = [\n",
    "                    SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                    RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "        ]\n",
    "        \n",
    "        walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=1, n=1, a=1,\n",
    "                c=1e-2, eps=1, target=target.cpu(), T=T)\n",
    "\n",
    "        x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "        e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "        for e_ in e.T[:10]:\n",
    "            plt.plot(e_)\n",
    "        plt.show()\n",
    "        sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "        for sim_ in sim.T[:10]:\n",
    "            plt.plot(sim_)\n",
    "        plt.show()\n",
    "        TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))\n",
    "    torch.save((x,TRACKS), f\"tracks_{gamma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7640a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T11:52:04.818797Z",
     "start_time": "2022-10-03T11:44:58.495523Z"
    }
   },
   "outputs": [],
   "source": [
    "for (track_e, track_s), (s, e) in zip(TRACKS,product(sim_plage,e_plage)):\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.subplot(121)\n",
    "    print(e,s)\n",
    "    for e_ in track_e[:5]:\n",
    "        plt.plot(-e_)\n",
    "    plt.plot([0,100],[.15,-e[0]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[0],-e[0]],color=\"black\")\n",
    "    plt.plot([0,100],[.15,-e[1]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[1],-e[1]],color=\"black\")\n",
    "    plt.ylabel(\"E_RBM\")\n",
    "    plt.xlabel(\"Langevin Dynamic Step\")\n",
    "\n",
    "    #plt.show()\n",
    "    plt.subplot(122)\n",
    "    for sim_ in track_s[:5]:\n",
    "        plt.plot(sim_)\n",
    "    plt.plot([0,100],[0,s[0]],color=\"black\")\n",
    "    plt.plot([100,200],[s[0],s[0]],color=\"black\")\n",
    "    plt.plot([0,100],[0,s[1]],color=\"black\")\n",
    "    plt.plot([100,200],[s[1],s[1]],color=\"black\")\n",
    "    \n",
    "    plt.ylabel(\"Distance to SpyCas9\")\n",
    "    plt.xlabel(\"Langevin Dynamic Step\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b4a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-14T15:06:04.285884Z",
     "start_time": "2022-12-14T15:06:03.431186Z"
    }
   },
   "outputs": [],
   "source": [
    "e = []\n",
    "eb = []\n",
    "sim = []\n",
    "fx = []\n",
    "fx_dna = []\n",
    "crit = []\n",
    "best_sim = []\n",
    "for x_ in tqdm_notebook(x):\n",
    "    sim.append((x_.reshape(len(x_),21,-1).argmax(1) != walker.x0.argmax(1)).sum(-1))\n",
    "    e.append((walker.model({\"pi\" : x_.reshape(len(x_),21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)-a * sim[-1]-b)\n",
    "    fx_dna.append(foldx_energy_with_dna(x_.reshape(-1,21,736), [deepcopy(structure_complex) for _ in x_]))\n",
    "    crit.append(criterion(x_))\n",
    "    sim[-1] = sim[-1]+0.1 * torch.randn(len(sim[-1]))\n",
    "    eb.append((walker.model({\"pi\" : x_.reshape(len(x_),21,-1)[:,:,walker.kept_idx]})/736 - walker.Z))\n",
    "torch.save(fx_dna, \"all_fx_dna.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59378ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:23:41.561490Z",
     "start_time": "2023-01-20T18:23:41.486377Z"
    }
   },
   "outputs": [],
   "source": [
    "fx_dna = torch.load(\"/home/malbranke/cas9/all_fx_dna.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dec803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T14:35:37.521551Z",
     "start_time": "2022-12-22T14:08:15.019269Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma = 0\n",
    "x = []\n",
    "TRACKS = []\n",
    "folder = \"/home/malbranke/data/cas9/vink\"\n",
    "a=b=0\n",
    "for gamma in sorted(gammas)[:10]:\n",
    "    model_full_name = f\"rbmssl2_pid_h{Nh}_npam{Npam}_gamma{gamma}\"\n",
    "\n",
    "    model_rbm = PI_RBM_SSL(classifier, layers= {pi.name: pi, h.name: h}, edges=E, name = model_full_name)\n",
    "    model_rbm = model_rbm.to(device)\n",
    "    model_rbm.load(f\"{folder}/weights/{model_full_name}_{best_epoch}.h5\")\n",
    "    model_rbm.eval()\n",
    "    model_rbm.ais()\n",
    "    model_rbm = model_rbm.to(\"cpu\")\n",
    "\n",
    "    target = litpam_to_pam(\"NGG\").to(device)\n",
    "    edge = model_rbm.edges[\"pi -> hidden\"]\n",
    "    model_rbm = model_rbm.to(device)\n",
    "\n",
    "    idx0 = 0\n",
    "    idx = (idx0*torch.ones(512).int()).to(device)\n",
    "\n",
    "    criterion = classifier_criterion(classifier, edge, target)\n",
    "    x__ = torch.cat([X_rbm[0][None] for i in idx],0)\n",
    "\n",
    "    x_cas9 = torch.clone(x__[0].view(-1))\n",
    "    h_cas9 = edge(x_cas9[None], False)\n",
    "\n",
    "\n",
    "    sim_plage = [(5*i,5*i+5) for i in range(2,10)]\n",
    "    with torch.no_grad():\n",
    "        e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "    e_plage = [(e0-0.02, e0+0.02)]\n",
    "\n",
    "    for s, e in product(sim_plage,e_plage):\n",
    "        main = None\n",
    "        criterions = [\n",
    "                    SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                    RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "        ]\n",
    "        T = 0.1*torch.ones(1,1,len(kept_idx))\n",
    "        walker = Walker(x_cas9.view(21,-1).clone(), model_rbm, main, criterions, zero_idx, gamma=.1,\n",
    "                        n=1, a = .3, c=1e-4, eps=.03, T = T, n_samples = 8, target = target.cpu())\n",
    "        x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "        e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "        for e_ in e.T[:10]:\n",
    "            plt.plot(e_)\n",
    "        plt.show()\n",
    "        sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "        for sim_ in sim.T[:10]:\n",
    "            plt.plot(sim_)\n",
    "        plt.show()\n",
    "        TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))\n",
    "torch.save((x,TRACKS), f\"tracks_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c60f2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T16:13:46.664Z"
    }
   },
   "outputs": [],
   "source": [
    "e = []\n",
    "eb = []\n",
    "sim = []\n",
    "fx = []\n",
    "fx_dna_0 = []\n",
    "crit = []\n",
    "best_sim = []\n",
    "for x_ in tqdm_notebook(x):\n",
    "    sim.append((x_.reshape(len(x_),21,-1).argmax(1) != walker.x0.argmax(1)).sum(-1))\n",
    "    e.append((walker.model({\"pi\" : x_.reshape(len(x_),21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)-a * sim[-1]-b)\n",
    "    fx_dna_0.append(foldx_energy_with_dna(x_.reshape(-1,21,736), [deepcopy(structure_complex) for _ in x_]))\n",
    "    crit.append(criterion(x_))\n",
    "    sim[-1] = sim[-1]+0.1 * torch.randn(len(sim[-1]))\n",
    "    eb.append((walker.model({\"pi\" : x_.reshape(len(x_),21,-1)[:,:,walker.kept_idx]})/736 - walker.Z))\n",
    "torch.save(fx_dna_0, \"all_fx_dna_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76da795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:25:05.307406Z",
     "start_time": "2023-01-20T18:25:05.299889Z"
    }
   },
   "outputs": [],
   "source": [
    "fx_dna_0 = torch.load(\"/home/malbranke/cas9/all_fx_dna_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe604be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T12:55:40.895899Z",
     "start_time": "2022-12-16T12:55:40.882743Z"
    }
   },
   "outputs": [],
   "source": [
    "values = (torch.stack(fx_dna,0)<82).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,:].mean((-1,-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121d719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:38:28.094203Z",
     "start_time": "2023-01-20T18:38:28.089268Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149bc1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:40:09.220891Z",
     "start_time": "2023-01-20T18:40:09.215893Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_gammas_inv = {v:k for k,v in enumerate(selected_gammas)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c1f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:41:09.328893Z",
     "start_time": "2023-01-20T18:41:09.319531Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_gammas_inv[50.36340233637961], selected_gammas_inv[8.232271190763177], selected_gammas_inv[0.05669391237529596]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf7798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:42:46.972792Z",
     "start_time": "2023-01-20T18:42:46.963677Z"
    }
   },
   "outputs": [],
   "source": [
    "fx_dna_stacked = torch.stack(fx_dna,0).reshape(len(selected_gammas), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd6962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T20:11:51.444666Z",
     "start_time": "2023-01-20T20:11:50.413541Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.hist(torch.stack(fx_dna_0,0).flatten(), bins = np.arange(65, 100, 5), density=True)\n",
    "plt.ylim(0,0.06)\n",
    "#plt.plot([torch.stack(fx_dna_0,0).flatten().mean(),torch.stack(fx_dna_0,0).flatten().mean()],[0,0.1])\n",
    "plt.subplot(132)\n",
    "plt.hist(fx_dna_stacked[120:140].flatten(), bins = np.arange(65, 100, 5), density = True)\n",
    "plt.ylim(0, 0.06)\n",
    "plt.yticks(np.arange(0,0.07,0.01), [\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.hist(fx_dna_stacked[240:250].flatten(), bins = np.arange(65, 100, 5), density = True)\n",
    "plt.ylim(0, 0.06)\n",
    "plt.yticks(np.arange(0,0.07,0.01), [\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e4239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:44:07.855658Z",
     "start_time": "2023-01-20T18:44:07.081169Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519e1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930649a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:38:32.259227Z",
     "start_time": "2023-01-20T18:38:30.552691Z"
    }
   },
   "outputs": [],
   "source": [
    "n=20\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "thresholds = [70, 75, 80, 85]\n",
    "colors = [\"blue\", \"red\", \"green\", \"orange\"]\n",
    "legends = [f\"fx_dna < {thr}\" for thr in thresholds]\n",
    "for thr, c in zip(thresholds, colors):\n",
    "    values0 = (torch.stack(fx_dna_0,0)<thr).int().float()[:,:].mean()\n",
    "    values = (torch.stack(fx_dna,0)<thr).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,:].mean((-1,-2))\n",
    "    fvalues = gaussian_filter1d(values[1:],n, mode=\"nearest\")\n",
    "    errors = np.array([np.std(values[i:i+n].numpy()) for i in range(1,len(values)-n)])\n",
    "    plt.plot(selected_gammas[1:], gaussian_filter1d(values[1:],n,  mode=\"nearest\"), c=c)\n",
    "    #plt.plot([0,1000], [values0,values0], linestyle='dashed', c=c)\n",
    "    plt.fill_between(selected_gammas[n//2+1:-n//2], fvalues[n//2:-n//2]-errors, fvalues[n//2:-n//2]+errors, color=c, alpha = 0.2)\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "plt.plot([0,0], [values0,values0], linestyle='dashed', c=\"gray\")\n",
    "\n",
    "for thr, c in zip(thresholds, colors):\n",
    "    values0 = (torch.stack(fx_dna_0,0)<thr).int().float()[:,:].mean()\n",
    "    values = (torch.stack(fx_dna,0)<thr).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,:].mean((-1,-2))\n",
    "    fvalues = gaussian_filter1d(values[1:],n, mode=\"nearest\")\n",
    "    errors = np.array([np.std(values[i:i+n].numpy()) for i in range(1,len(values)-n)])\n",
    "    #plt.plot(selected_gammas[1:], gaussian_filter1d(values[1:],n,  mode=\"nearest\"), c=c)\n",
    "    plt.plot([0,1000], [values0,values0], linestyle='dashed', c=c)\n",
    "    #plt.fill_between(selected_gammas[n//2+1:-n//2], fvalues[n//2:-n//2]-errors, fvalues[n//2:-n//2]+errors, color=\"blue\", alpha = 0.2)\n",
    "    plt.xscale(\"log\")\n",
    "legends = [f\"fx_dna < {thr}\" for thr in thresholds]+[\"with standard RBM \\n(gamma = 0)\"]\n",
    "plt.legend(legends, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.xlabel(\"Gamma (strength of the classifier)\")\n",
    "plt.ylabel(\"Share of sequences\")\n",
    "plt.xlim(0.05,50)\n",
    "plt.title(\"Share of sequences with FoldX energy below thresholds \\n(wild type FoldX energy: 67.43)\", fontsize=12)\n",
    "\n",
    "plt.ylim(0.,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593b1ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T17:18:53.479426Z",
     "start_time": "2022-12-16T17:18:52.216812Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import *\n",
    "\n",
    "n=20\n",
    "values0 = (torch.stack(fx_dna_0,0)).float()[:,:].mean()\n",
    "values = (torch.stack(fx_dna,0)).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,:].mean((-1,-2))\n",
    "fvalues = gaussian_filter1d(values[1:],n, mode=\"nearest\")\n",
    "errors = np.array([np.std(values[i:i+n].numpy()) for i in range(1,len(values)-n)])\n",
    "plt.plot(selected_gammas[1:], gaussian_filter1d(values[1:],n,  mode=\"nearest\"), c=\"blue\")\n",
    "plt.plot([0,1000], [values0,values0], c=\"black\")\n",
    "\n",
    "plt.fill_between(selected_gammas[n//2+1:-n//2], fvalues[n//2:-n//2]-errors, fvalues[n//2:-n//2]+errors, color=\"blue\", alpha = 0.2)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Gamma (strength of the classifier)\")\n",
    "plt.ylabel(\"Mean FoldX energy with DNA\")\n",
    "#plt.ylim(80,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4463541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T12:50:09.351739Z",
     "start_time": "2022-12-16T12:50:08.049683Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(selected_gammas, (torch.stack(fx_dna,0)<82).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,-5:].mean((-1,-2)))\n",
    "plt.xscale(\"log\")\n",
    "#plt.xlim(1e-3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f183397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-11T18:16:35.431704Z",
     "start_time": "2022-12-11T18:16:33.975481Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(selected_gammas, (torch.stack(fx_dna,0)<80).reshape(len(selected_gammas), len(sim_plage), -1).int().float()[:,-5:].mean((-1,-2)))\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(1e-3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09415a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:58:24.190678Z",
     "start_time": "2022-10-04T08:58:24.178504Z"
    }
   },
   "outputs": [],
   "source": [
    "labelled_crit = criterion(X_labelled.reshape(-1,21,736))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434dc1c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T09:00:58.191347Z",
     "start_time": "2022-10-04T08:58:25.270166Z"
    }
   },
   "outputs": [],
   "source": [
    "labelled_fx = foldx_energy(X_labelled.reshape(-1,21,736), [deepcopy(structure_alone) for _ in X_labelled])\n",
    "labelled_fx_dna = foldx_energy_with_dna(X_labelled.reshape(-1,21,736), [deepcopy(structure_complex) for _ in X_labelled])\n",
    "#labelled_fx_dna_AA = foldx_energy_with_dna(X_labelled.reshape(-1,21,736), [deepcopy(structure_complex_AA) for _ in X_labelled])\n",
    "colors = [\"red\",\"darkorange\",\"gold\",\"green\"]\n",
    "\n",
    "def mcherry_threshold(x):\n",
    "    if x < 0.2:\n",
    "        return 0\n",
    "    if x < 0.5:\n",
    "        return 1\n",
    "    if x < 0.8:\n",
    "        return 2\n",
    "    return 3\n",
    "functionality = df[df.batch  >= 0][\"mcherry\"].apply(lambda x:colors[mcherry_threshold(x)]).values\n",
    "functionality_number = df[df.batch  >= 0][\"mcherry\"].apply(lambda x:mcherry_threshold(x)).values\n",
    "\n",
    "\n",
    "labelled_ebrbm = (walker.model({\"pi\" : X_labelled.reshape(len(X_labelled),21,-1)[:,:,walker.kept_idx]})/736 - walker.Z).detach()\n",
    "labelled_diff = df[df.batch>=0][\"sim_cas9\"]\n",
    "\n",
    "normfl = df[df.batch>=0][\"mcherry\"].values\n",
    "labels = df[df.batch>=0][\"functional\"].apply(lambda x : int(x))\n",
    "\n",
    "labelled_colors = np.array([colors[i] for i in labels])\n",
    "#labelled_erbm = (labelled_ebrbm - clf.predict(labelled_diff[:,None]))\n",
    "#e = torch.cat(eb,0).detach() - clf.predict(torch.cat(sim,0).detach()[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eae976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T09:06:11.370767Z",
     "start_time": "2022-10-04T09:06:09.930509Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from scipy.stats import *\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    #y = clf.predict([[0],[200]])\n",
    "    print(spearmanr(normfl,labelled_ebrbm))\n",
    "    plt.figure(figsize = (7,7))\n",
    "    plt.scatter(torch.cat(sim,0).detach(),-torch.cat(eb,0).detach(), color = \"lightgray\",s=7)\n",
    "    plt.scatter(labelled_diff, -labelled_ebrbm, color=labelled_colors)\n",
    "   # plt.plot([0,200],y, c=\"black\")\n",
    "    plt.scatter([0], (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z), marker=\"+\", color = \"black\", s = 160)\n",
    "   # plt.title(f\"Spearman = {spearmanr(normfl,labelled_ebrbm)[0]:.3f}\")\n",
    "    plt.xlim(-1,100)\n",
    "    plt.ylim(0.14,0.26)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Distance to SpyCas9 PID\", size = 16, )\n",
    "    plt.ylabel(\"RBM\", size = 16, )\n",
    "    #plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b90973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T09:05:44.826803Z",
     "start_time": "2022-10-04T09:05:44.816532Z"
    }
   },
   "outputs": [],
   "source": [
    "e0 = (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)-a * 0-b\n",
    "eb0 = (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfef1ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T15:45:02.044256Z",
     "start_time": "2022-09-09T15:44:57.912824Z"
    }
   },
   "outputs": [],
   "source": [
    "e0 = (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)-a * 0-b\n",
    "eb0 = (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z)\n",
    "\n",
    "sim0 = 0\n",
    "structure_alone = Structure(code=\"model\", path = f\"/home/malbranke/data/foldx/cas9_pid.pdb\")\n",
    "fx0 = foldx_energy_with_dna(walker.x0.reshape(-1,21,736), [deepcopy(structure_alone)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17211b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T15:45:03.970157Z",
     "start_time": "2022-09-09T15:45:03.921181Z"
    },
    "code_folding": [
     24
    ]
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import pandas as pd \n",
    "\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "freq_df = pd.read_excel(f\"{DATA}/cas9/codon_frequency_ecoli.xlsx\")\n",
    "freq_dict = {k:[] for k in AA}\n",
    "codon_dict = {k:[] for k in AA}\n",
    "\n",
    "for aa, codon, freq in zip(freq_df.aa, freq_df.codon, freq_df.frequency):\n",
    "    if aa not in AA:\n",
    "        continue\n",
    "    if freq > 0.1:\n",
    "        freq_dict[aa].append(float(freq))\n",
    "        codon_dict[aa].append(codon)\n",
    "for aa in AA:\n",
    "    freq_dict[aa] = np.array(freq_dict[aa])/sum(freq_dict[aa])\n",
    "    freq_dict[aa] = np.cumsum(freq_dict[aa])\n",
    "\n",
    "start_seq = \"AAACACGTGGCAAACATTCCttGGTCTCtAAAAGACTGAGGTACAG\"\n",
    "end_seq = \"CGTATTGATCTGAGTCAGTTGGGCGGTGACTAATAAGGAGAGACCAAGTACTGTATGGCTCCGGTTT\"\n",
    "forbiddens = [\"GGTCTC\",\"GAGACC\",\"CGTCTC\",\"GAGACG\"]\n",
    "\n",
    "def aa_to_dna(x):\n",
    "    dna_seq = start_seq\n",
    "    for i, aa in enumerate(x):\n",
    "        n_try = 0\n",
    "        while True:\n",
    "            if n_try > 5:\n",
    "                print(\"try again\")\n",
    "                return aa_to_dna(x)\n",
    "            u = random()\n",
    "            codon_idx = (u > freq_dict[aa]).sum()\n",
    "            codon = codon_dict[aa][codon_idx]\n",
    "            stop = True\n",
    "            for forbidden in forbiddens:\n",
    "                if (i+1) == len(x):\n",
    "                    if forbidden in (dna_seq[-5:]+codon+end_seq[:5]):\n",
    "                        stop = False\n",
    "                else:\n",
    "                    if forbidden in (dna_seq[-5:]+codon):\n",
    "                        stop = False\n",
    "            if not stop:\n",
    "                n_try +=1\n",
    "                continue\n",
    "            dna_seq+=codon\n",
    "            break\n",
    "    dna_seq += end_seq\n",
    "    return dna_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbecec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T09:05:50.350644Z",
     "start_time": "2022-10-04T09:05:49.503176Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    df[\"seq\"] = [\"\".join(AA[i-1] for i in x_) for x_ in torch.cat(x,0).view(-1, 21,N)[:,:,nnz_idx].argmax(1).detach().numpy()]\n",
    "    df[\"dna_seq\"] = df[\"seq\"].apply(lambda x : aa_to_dna(x))\n",
    "    df[\"sim_cas9\"] = torch.cat(sim,0).numpy()\n",
    "    df[\"best_sim\"] = torch.cat(best_sim,0).numpy()\n",
    "    df[\"e_rbm\"] = torch.cat(eb,0).numpy()\n",
    "    df[\"e_rbm_unbiaised\"] = e.numpy()\n",
    "    df[\"fx\"] = torch.cat(fx,0).numpy()\n",
    "    df[\"fx_dna\"] = torch.cat(fx_dna,0).numpy()\n",
    "    df[\"fx_dna_AA\"] = torch.cat(fx_dna_AA,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5caa1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ab257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T08:56:46.160132Z",
     "start_time": "2022-06-09T08:56:46.043191Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.to_excel(\"batch3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b206a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T09:05:55.683867Z",
     "start_time": "2022-10-04T09:05:54.297064Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "with torch.no_grad():\n",
    "\n",
    "    idx = torch.where(torch.cat(sim,0)>20)[0]\n",
    "    plt.scatter(-torch.cat(eb,0)[idx],torch.cat(fx_dna,0).detach()[idx], color = \"lightgray\",s=7)\n",
    "    plt.scatter([-x for x in labelled_ebrbm[np.where(labelled_diff > 0)]],labelled_fx_dna[np.where(labelled_diff > 0)], color=labelled_colors[np.where(labelled_diff > 0)], s=25)\n",
    "    #plt.plot([-0.5,0.1],[85,85], \"--\", color = \"red\")\n",
    "    #plt.plot([-0.22,-0.22],[10,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(0.14,0.26)\n",
    "    plt.ylim(55,200)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"RBM score\", size = 16, )\n",
    "    plt.ylabel(\"Fx energy with DNA\", size = 16, )\n",
    "    #plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccdd4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T11:27:44.229859Z",
     "start_time": "2022-09-13T11:27:43.866847Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "with torch.no_grad():\n",
    "\n",
    "    idx = torch.where(torch.cat(sim,0)>0)[0]\n",
    "    plt.scatter(-torch.cat(eb,0)[idx],torch.cat(crit,0).detach()[idx].exp(), color = \"lightgray\",s=7)\n",
    "    plt.scatter([-x for x in labelled_ebrbm[np.where(labelled_diff > 0)]],np.exp(labelled_crit[np.where(labelled_diff > 0)]), color=labelled_colors[np.where(labelled_diff > 0)], s=25)\n",
    "    #plt.plot([-0.5,0.1],[85,85], \"--\", color = \"red\")\n",
    "    #plt.plot([-0.22,-0.22],[10,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(0.15,0.3)\n",
    "   # plt.ylim(65,200)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"RBM score\", size = 16, )\n",
    "    plt.ylabel(\"Crit\", size = 16, )\n",
    "    #plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73aac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T15:45:13.025566Z",
     "start_time": "2022-09-09T15:45:12.534909Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,22))\n",
    "with torch.no_grad():\n",
    "    plt.subplot(321)\n",
    "    #y = clf.predict([[0],[200]])\n",
    "    plt.scatter(torch.cat(sim,0).detach(),torch.cat(eb,0), color = \"lightgray\",s=7)\n",
    "    plt.scatter(labelled_diff, labelled_ebrbm, color=labelled_colors)\n",
    "    #plt.scatter(df_final.sim_cas9, df_final.e_rbm, color = \"blue\")\n",
    "    plt.scatter([0], (walker.model({\"pi\" : walker.x0.reshape(1,21,-1)[:,:,walker.kept_idx]})/736 - walker.Z), marker=\"+\", color = \"black\", s = 160)\n",
    "    plt.title(f\"Spearman = {spearmanr(normfl,labelled_erbm)[0]:.3f}\")\n",
    "    plt.xlim(-1,100)\n",
    "    plt.ylim(-0.3,0)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Sim\", size = 16, )\n",
    "    plt.ylabel(\"RBM\", size = 16, )\n",
    "    \n",
    "    plt.subplot(322)\n",
    "    idx = torch.where(torch.cat(sim,0)>0)[0]\n",
    "    plt.scatter(torch.cat(fx,0).detach()[idx]-80,torch.cat(fx_dna,0).detach()[idx], color = \"lightgray\",s=10)\n",
    "    plt.scatter(labelled_fx[np.where(labelled_diff > 0)]-80, labelled_fx_dna[np.where(labelled_diff > 0)], color=labelled_colors[np.where(labelled_diff > 0)], s=15)\n",
    "\n",
    "    #plt.scatter(df_final.fx-80, df_final.fx_dna, color = \"blue\")\n",
    "    plt.plot([0,500],[50,50], \"--\", color = \"red\")\n",
    "    plt.plot([45,45],[0,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(9,500)\n",
    "    plt.ylim(9,500)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Fx energy\", size = 16, )\n",
    "\n",
    "    plt.ylabel(\"Fx energy with DNA\", size = 16, )\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(323)\n",
    "    idx = torch.where(torch.cat(sim,0)>0)[0]\n",
    "    plt.scatter(torch.cat(eb,0)[idx],torch.cat(fx,0).detach()[idx]-80, color = \"lightgray\",s=10)\n",
    "    plt.scatter(labelled_ebrbm[np.where(labelled_diff > 0)],labelled_fx[np.where(labelled_diff > 0)]-80, color=labelled_colors[np.where(labelled_diff > 0)], s=15)\n",
    "    #plt.scatter(df_final.e_rbm_unbiaised, df_final.fx-80, color = \"blue\")\n",
    "\n",
    "    #plt.scatter([eb0-clf.predict([[0]])[0]], [fx0-80], marker=\"+\", color = \"black\", s = 160)\n",
    "    plt.plot([-0.5,0.1],[45,45], \"--\", color = \"red\")\n",
    "    plt.plot([-0.15,-0.15],[10,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(-0.3,0.)\n",
    "    plt.ylim(9,500)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Unbiased RBM\", size = 16, )\n",
    "    plt.ylabel(\"Fx energy\", size = 16, )\n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.subplot(324)\n",
    "    idx = torch.where(torch.cat(sim,0)>0)[0]\n",
    "    plt.scatter(torch.cat(eb,0)[idx],torch.cat(fx_dna,0).detach()[idx], color = \"lightgray\",s=10)\n",
    "    plt.scatter(labelled_ebrbm[np.where(labelled_diff > 0)],labelled_fx_dna[np.where(labelled_diff > 0)], color=labelled_colors[np.where(labelled_diff > 0)], s=15)\n",
    "    plt.plot([-0.5,0.1],[50,50], \"--\", color = \"red\")\n",
    "    plt.plot([-0.15,-0.15],[10,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(-0.3,0.)\n",
    "    plt.ylim(9,500)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Unbiased RBM\", size = 16, )\n",
    "    plt.ylabel(\"Fx energy with DNA\", size = 16, )\n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.subplot(325)\n",
    "    idx = torch.where(torch.cat(sim,0)>0)[0]\n",
    "    plt.scatter(torch.cat(eb,0)[idx],torch.cat(fx_dna,0).detach()[idx], color = \"lightgray\",s=10)\n",
    "    plt.scatter(labelled_ebrbm[np.where(labelled_diff > 0)],labelled_fx_dna[np.where(labelled_diff > 0)], color=labelled_colors[np.where(labelled_diff > 0)], s=15)\n",
    "\n",
    "    plt.plot([-0.5,0.1],[50,50], \"--\", color = \"red\")\n",
    "    plt.plot([-0.15,-0.15],[10,500], \"--\", color = \"green\")\n",
    "\n",
    "    plt.xlim(-0.3,0.)\n",
    "    plt.ylim(9,500)\n",
    "    plt.xticks(size = 14, rotation = 45)\n",
    "    plt.yticks(size = 14)\n",
    "    plt.xlabel(\"Unbiased RBM\", size = 16, )\n",
    "    plt.ylabel(\"Fx energy with DNA\", size = 16, )\n",
    "    plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a58e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T16:18:12.144916Z",
     "start_time": "2022-05-13T16:18:11.409157Z"
    },
    "code_folding": [
     23,
     41,
     52,
     70,
     80,
     101,
     113,
     119,
     125,
     129,
     145,
     240,
     256,
     352
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pyfoldx as foldx\n",
    "from pyfoldx.structure import Structure\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "W = edge.get_weights()[None]\n",
    "from torch.distributions.one_hot_categorical import OneHotCategorical\n",
    "NAd_in = {\"A\":\"A\", \"T\":\"T\", \"C\":\"C\", \"G\":\"G\",\n",
    "          \"W\":\"AT\", \"S\":\"CG\", \"M\":\"AC\", \"K\":\"TG\", \"R\":\"AG\", \"Y\":\"TC\",\n",
    "           \"B\":\"TCG\", \"D\":\"ATG\", \"H\":\"ATC\", \"V\": \"ACG\", \"N\":\"ATCG\"}\n",
    "NAd = [\"O\",\"A\",\"T\",\"W\",\"C\",\"M\",\"Y\",\"H\",\"G\",\"R\",\"K\",\"D\",\"S\",\"V\",\"B\",\"N\"]\n",
    "\n",
    "pl3to1 = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N', \n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W', \n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "pl1to3 = {v:k for k,v in pl3to1.items()}\n",
    "\n",
    "\n",
    "def aux(args):\n",
    "    seq, struct, repair = args\n",
    "    chain = \"A\"\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1\n",
    "    for target in seq[:]:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    return float(s_new.getTotalEnergy().loc[\"model\"][\"total\"])\n",
    "\n",
    "def foldx_energy(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        energies = pool.map(aux, list(zip(seqs, structs, repairs,)))\n",
    "    #energies = [aux(seq, struct, repair) for seq, struct, repair in zip(seqs, structs, repairs)]\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def aux_with_dna(args):\n",
    "    seq, struct, repair, = args\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1103\n",
    "    chain = \"B\"\n",
    "    for target in seq[1:]:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    return float(s_new.getTotalEnergy().loc[\"model\"][\"total\"])\n",
    "\n",
    "def foldx_energy_with_dna(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        energies = pool.map(aux_with_dna, list(zip(seqs, structs, repairs,)))\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def aux_with_dna_interface(args):\n",
    "    seq, struct, repair, = args\n",
    "    do_repair, idx = repair\n",
    "    s =  struct\n",
    "    s_new =  struct\n",
    "    position = 1\n",
    "    chain = \"A\"\n",
    "    for target in seq[:]:\n",
    "        try:\n",
    "            if position in s.data[chain].keys():\n",
    "                res = s.data[chain][position]\n",
    "                res.code = pl1to3[target]\n",
    "                s_new.data[chain][position] = res\n",
    "        except:\n",
    "            ()\n",
    "        position += 1\n",
    "    if do_repair:\n",
    "        #s_new.repair()\n",
    "        structures[idx] = deepcopy(s_new)\n",
    "    return float(s_new.getInterfaceEnergy(verbose=False)[\"Interaction Energy\"].loc[\"B\"].loc[\"D\"])\n",
    "\n",
    "def interface_energy_with_dna(x_sampled, structs, repair=False, ):\n",
    "    seqs = []\n",
    "    repairs = []\n",
    "    for i, x in enumerate(x_sampled):\n",
    "        seqs.append([AA[x_] for x_ in x[1:,nnz_idx].cpu().argmax(0)])\n",
    "        repairs.append((repair,i))\n",
    "    with multiprocessing.Pool(processes = 32) as pool:\n",
    "        structs = [deepcopy(s) for s in structs]\n",
    "        energies = pool.map(aux_with_dna_interface, list(zip(seqs, structs, repairs,)))\n",
    "    #energies = [aux(seq, struct, repair) for seq, struct, repair in zip(seqs, structs, repairs)]\n",
    "    return torch.tensor(energies)\n",
    "\n",
    "def abs_diff(x, x0):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    x0 = x0.reshape(x0.size(0),21,-1)\n",
    "\n",
    "    return (x[:,:,nnz_idx].argmax(1) != x0[:,:,nnz_idx].argmax(1)).int().float().sum(-1)\n",
    "\n",
    "def mean_diff(x, x0):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    x0 = x0.reshape(x0.size(0),21,-1)\n",
    "\n",
    "    return (x[:,:,nnz_idx].argmax(1) != x0[:,:,nnz_idx].argmax(1)).int().float().mean(-1)\n",
    "\n",
    "def isd(x):\n",
    "    x = x.reshape(x.size(0),21,-1)\n",
    "    return (x[:,0,nnz_idx].mean(-1)) + (1-(x[:,0,zero_idx].mean(-1)))\n",
    "\n",
    "def classifier_criterion(classifier, edge, target):\n",
    "    target = target\n",
    "    def crit(x):\n",
    "        p = classifier(edge(x, False)).sigmoid()\n",
    "        #return torch.ones(p.size(0))\n",
    "        #return (target * (p+1e-7).log()).mean(-1)\n",
    "        return (target * (p+1e-7).log() + (1-target) * (1-p+1e-7).log()).mean(-1)\n",
    "    return crit\n",
    "\n",
    "def litpam_to_pam(s):\n",
    "    pam = []\n",
    "    s += \"N\"*max(0,(Npam-len(s)))\n",
    "    for x in s:\n",
    "        pam += NAd_idx[x]\n",
    "    return torch.tensor(pam).float()[None].to(device)\n",
    "\n",
    "def get_direction(model_rbm, edge, target, x, h, a, c, T=1e-1, step = 0):\n",
    "    samples = 16\n",
    "    x0 = x[None].expand(samples,-1,-1).reshape(samples*x.size(0), 21, -1)\n",
    "    mut = edge.reverse(h[None].expand(samples,-1,-1).reshape(-1,Nh))\n",
    "    mut = mut.reshape(mut.size(0),21,-1)\n",
    "\n",
    "    mut[:,0] = -10000\n",
    "    mut[:,0,zero_idx] = 10000\n",
    "\n",
    "    phi = (mut + pi.linear.weight.view(1, pi.q, pi.N))/(1e-1)\n",
    "    distribution = OneHotCategorical(probs=F.softmax(phi, 1).permute(0,2,1))\n",
    "    x_sampled = distribution.sample().permute(0, 2, 1)\n",
    "    x_sampled[:,:,zero_idx] = x_sampled.reshape(x_sampled.size(0), 21, -1)[:,:,zero_idx].detach()\n",
    "    h_sampled = edge(x_sampled, False).reshape(samples, -1, Nh).permute(1,0,2)\n",
    "    \n",
    "    Z = model_rbm.Z.cpu().item()\n",
    "    N = pi.N\n",
    "    hs = [h_.detach() for h_ in h_sampled]\n",
    "    for h_ in hs:\n",
    "        h_.requires_grad = True\n",
    "    p = [classifier(h_).sigmoid() for h_ in hs]\n",
    "    crits = [((target * (p_+1e-7).log() + (1-target) * (1-p_+1e-7).log()).mean(-1)).mean(0) for p_ in p]\n",
    "    #crits = [((target * (p_+1e-7).log()).mean(-1)).mean(0) for p_ in p]\n",
    "\n",
    "    TRACK[\"|h|\"].append(h.detach().pow(2).sum(-1).sqrt()/h.size(-1))\n",
    "    [crit_.backward() for crit_ in crits]\n",
    "    gradient_C = torch.stack([h_.grad.mean(0) for h_ in hs],0)\n",
    "    with torch.no_grad():\n",
    "        structures = [deepcopy(struct_cas9) for _ in range(x.size(0)*samples)]\n",
    "        structures_with_dna = [deepcopy(struct_cas9_with_dna) for _ in range(x.size(0)*samples)]\n",
    "        structures_with_dna_AA = [deepcopy(struct_cas9_with_dna_AA) for i in range(x.size(0)*samples)]\n",
    "        Wv = edge(x_sampled,False).reshape(samples,x.size(0),-1)\n",
    "        Wv_ = Wv.mean(0)\n",
    "\n",
    "        # RBM Energy (Not too far from natural)\n",
    "        pv = (model_rbm({\"pi\":x_sampled}).reshape(samples,x.size(0),-1)/N - Z)\n",
    "        phi1 = F.relu(min_edca - pv).abs()\n",
    "        phi1_ = phi1.mean(0)\n",
    "        gradient_phi1 = ((Wv-Wv_)*(phi1-phi1_)).mean(0)\n",
    "        TRACK[\"E(log P(x))\"].append(pv.mean(0))\n",
    "        \n",
    "        # Slow down\n",
    "        sim = abs_diff(x_sampled, x0).reshape(samples,x.size(0),-1)\n",
    "        phi2 = F.relu(sim - 5).pow(2)\n",
    "        phi2_ = phi2.mean(0)\n",
    "        gradient_phi2 = ((Wv-Wv_)*(phi2-phi2_)).mean(0)\n",
    "        TRACK[\"Diff\"].append(sim.mean(0))\n",
    "        \n",
    "        # Sim to cas9\n",
    "        diff_cas9 = abs_diff(x_sampled, x_cas9[None].expand(x_sampled.size(0),-1)).reshape(samples,x.size(0),-1)\n",
    "        target = 20\n",
    "        phi3 = F.relu(diff_cas9-55) + F.relu(45-diff_cas9)\n",
    "        phi3_ = phi3.mean(0)\n",
    "        gradient_phi3 = ((Wv-Wv_)*(phi3-phi3_)).mean(0)\n",
    "        TRACK[\"Diff cas9\"].append(diff_cas9.mean(0))\n",
    "        \n",
    "        # FoldX energy\n",
    "        structs = [deepcopy(structures[i//samples]) for i in range(x.size(0)*samples)]\n",
    "        fx = foldx_energy(x_sampled, structures).to(device).reshape(samples,x.size(0), -1)\n",
    "        min_fxe= 150-30 * 4 * (0.5-step)**2\n",
    "        phi4 = (fx - 116).pow(2)\n",
    "        phi4_ = phi4.mean(0)\n",
    "        gradient_phi4 = ((Wv-Wv_)*(phi4-phi4_)).mean(0)\n",
    "        TRACK[\"foldx\"].append(fx.mean(0))\n",
    "        \n",
    "        # FoldX energy in complex AA\n",
    "        fx_dna_AA = foldx_energy_with_dna(x_sampled, structures_with_dna_AA).to(device).reshape(samples,x.size(0), -1)\n",
    "        phi5 = -fx_dna_AA\n",
    "        phi5_ = phi5.mean(0)\n",
    "        gradient_phi5 = ((Wv-Wv_)*(phi5-phi5_)).mean(0)\n",
    "        \n",
    "        # FoldX energy in complex\n",
    "        min_fxe_dna = 40\n",
    "        structs_dna = [deepcopy(structures_with_dna[i//samples]) for i in range(x.size(0)*samples)]\n",
    "        fx_dna = foldx_energy_with_dna(x_sampled, structures_with_dna).to(device).reshape(samples,x.size(0), -1)\n",
    "        phi6 = -fx_dna\n",
    "        phi6_ = phi6.mean(0)\n",
    "        gradient_phi6 = ((Wv-Wv_)*(phi6-phi6_)).mean(0)\n",
    "        \n",
    "        gradient_C += 3*torch.randn_like(h) - c*h + 3*gradient_phi5 - 3*gradient_phi6 \n",
    "        phi = 0*phi1.mean(0)[:,0] + 0*phi3.mean(0)[:,0] + 0*phi2.mean(0)[:,0] + 0*phi4.mean(0)[:,0] + 0* phi6.mean(0)[:,0]\n",
    "        gradient_phi = 0*gradient_phi1 + 0*gradient_phi3 + 0*gradient_phi2 + 0*gradient_phi4 + 0*gradient_phi6\n",
    "\n",
    "        norm_phi2 = gradient_phi.pow(2).sum(-1).detach()\n",
    "        angle_C = (gradient_phi*gradient_C).sum(-1)\n",
    "        angle_h = (gradient_phi*h).sum(-1)\n",
    "        norm_GC = gradient_C.pow(2).sum(-1).sqrt()\n",
    "        a_prime = a\n",
    "        diff = phi/a_prime\n",
    "       # diff = F.relu(diff) - 0 * F.relu(-diff) * torch.rand_like(diff)\n",
    "        bt = diff+angle_C\n",
    "        idx = torch.where(norm_phi2 > 0)\n",
    "        bt[idx] = (bt[idx]/norm_phi2[idx]).clip(-100,100)\n",
    "    return bt[None], gradient_C[None], gradient_phi[None]\n",
    "\n",
    "def step_hidden(edge, classifier, x, h, a=10, c = 0.00001, T=1e-1, n = 1, step = 0):\n",
    "\n",
    "    bt, gradient_C, gradient_phi = get_direction(model_rbm, edge, target, x, h.detach(), a, c)\n",
    "    norm_GC = gradient_C.pow(2).sqrt().detach()\n",
    "    h = h[None].expand(n,*h.size())\n",
    "    n1 = 1\n",
    "    h = (h + a*n1*(gradient_C-c*h - bt[:,:,None]*gradient_phi)).view(h.size(0)*h.size(1), -1) \n",
    "    #print(((gradient_C+bt[:,None]*gradient_phi)-c*h).view(h.size(0), -1))\n",
    "    mut = edge.reverse(h).reshape(h.size(0),21,-1)\n",
    "    mut[:,0] = -10000\n",
    "    mut[:,0,zero_idx] = 10000\n",
    "    phi = (mut + pi.linear.weight.view(1, pi.q, pi.N))/T\n",
    "    distribution = OneHotCategorical(probs=F.softmax(phi, 1).permute(0, 2, 1))\n",
    "    x_emitted = distribution.sample().permute(0, 2, 1)\n",
    "    return h, x_emitted, gradient_C, gradient_phi\n",
    "\n",
    "def sampling_through_criterion_and_phi(model, x_0, criterion, classifier, target = 5, T = 1e-5, n_sampling = 500, verbose = 1):\n",
    "    edge = model.edges[\"pi -> hidden\"]\n",
    "    batch_size, q, N = x_0.size()\n",
    "    x_0 = x_0.view(batch_size, -1).float()\n",
    "    Z = model.Z.cpu().item()\n",
    "    state_e = model({\"pi\": x_0.float().to(model.device)}).detach().cpu()/N - Z\n",
    "    state_h = edge(x_0, False).detach()\n",
    "    state_x = x_0.clone()\n",
    "    state_p = criterion(x_0.clone())\n",
    "    state_diff = torch.ones(len(x_0))*45\n",
    "    state_dynamic = torch.ones(batch_size)\n",
    "    structures = [Structure(code=\"alone\", path = f\"/home/malbranke/data/foldx/cas9_pid.pdb\") for _ in range(batch_size)]\n",
    "    structures_with_dna_AA = [deepcopy(struct_cas9_with_dna_AA) for _ in range(batch_size)]\n",
    "    structures_with_dna = [deepcopy(struct_cas9_with_dna) for _ in range(batch_size)]\n",
    "\n",
    "    state_xs = []\n",
    "    n_mut = 0\n",
    "    a = .3\n",
    "    TRACK[\"chains\"] = [state_x]\n",
    "    n = 4\n",
    "    for i in range(1,n_sampling):\n",
    "        h, x_emitted, gradient_C, gradient_phi = step_hidden(edge, classifier, state_x, state_h, a, n=n, step = i/n_sampling)\n",
    "        p = criterion(x_emitted.clone())\n",
    "        x_emitted = x_emitted.float().cpu().reshape(-1, q, N)\n",
    "        x_emitted = x_emitted.reshape(x_emitted.size(0), -1)\n",
    "        TRACK[\"chains\"].append(x_emitted)\n",
    "        TRACK[\"C\"].append(p.exp().detach())\n",
    "\n",
    "        e = (model({\"pi\" : x_emitted.float().clone()})/N - Z).detach().cpu()\n",
    "        structures = [deepcopy(struct_cas9) for _ in x_emitted]\n",
    "        structures_with_dna = [deepcopy(struct_cas9_with_dna) for _ in x_emitted]\n",
    "        structures_with_dna_AA = [deepcopy(struct_cas9_with_dna_AA) for i in x_emitted]\n",
    "        \n",
    "        fx = foldx_energy(x_emitted.reshape(-1, q, N), structures, repair = True)\n",
    "        fx_dna = foldx_energy_with_dna(x_emitted.reshape(-1, q, N), structures_with_dna)\n",
    "        fx_dna_AA = foldx_energy_with_dna(x_emitted.reshape(-1, q, N), structures_with_dna_AA)\n",
    "        \n",
    "        min_fxe_dna = 45\n",
    "        min_fxe = 125\n",
    "        idx = torch.where(~((fx<min_fxe) & (fx_dna_AA<min_fxe_dna)))[0]\n",
    "        \n",
    "        diffs = fx_dna_AA-fx_dna\n",
    "        diffs[idx] = 1000\n",
    "        diffs = torch.cat([state_diff[:,None], diffs.reshape(-1,n)],-1)\n",
    "        max_idx = diffs.argmin(1)\n",
    "        \n",
    "        state_dynamic = (max_idx > 0).int() + 0.8 * state_dynamic\n",
    "        changed_idx = torch.where((max_idx > 0))[0]\n",
    "        kept_idx = torch.where(max_idx == 0)[0]\n",
    "        killed_idx = torch.where(torch.rand(batch_size) > state_dynamic)[0]\n",
    "        \n",
    "        probs = state_dynamic.cumsum(0)/state_dynamic.sum()\n",
    "        replaced_idx = torch.tensor([(probs < random.random()).sum().int().item() for _ in killed_idx])\n",
    "        if len(changed_idx):\n",
    "            state_x[changed_idx] = x_emitted[n * changed_idx + max_idx[changed_idx] - 1]\n",
    "            state_h[changed_idx] = h[n * changed_idx + max_idx[changed_idx] - 1]\n",
    "            state_p[changed_idx] = p[n * changed_idx + max_idx[changed_idx] - 1]\n",
    "            state_e[changed_idx] = e[n * changed_idx + max_idx[changed_idx] - 1]\n",
    "            state_diff[changed_idx] = diffs[changed_idx, max_idx[changed_idx]]\n",
    "        if len(killed_idx):\n",
    "            state_x[killed_idx] = x_emitted[n * replaced_idx + max_idx[replaced_idx] - 1]\n",
    "            state_h[killed_idx] = h[n * replaced_idx + max_idx[replaced_idx] - 1]\n",
    "            state_p[killed_idx] = p[n * replaced_idx + max_idx[replaced_idx] - 1]\n",
    "            state_e[killed_idx] = e[n * replaced_idx + max_idx[replaced_idx] - 1]\n",
    "            state_diff[killed_idx] = diffs[replaced_idx, max_idx[replaced_idx]]\n",
    "            state_dynamic[killed_idx] = state_dynamic[replaced_idx]\n",
    "\n",
    "        structures = [deepcopy(struct_cas9) for _ in range(batch_size)]\n",
    "        structures_with_dna = [deepcopy(struct_cas9_with_dna) for _ in range(batch_size)]\n",
    "        structures_with_dna_AA = [deepcopy(struct_cas9_with_dna_AA) for _ in range(batch_size)]\n",
    "\n",
    "        n_mut+=len(changed_idx)\n",
    "        norm_GC, norm_Gphi, angle = gradient_C.pow(2).sum(-1).sqrt().detach(), gradient_phi.pow(2).sum(-1).sqrt().detach(), (gradient_C*gradient_phi).sum(-1).detach()\n",
    "        \n",
    "        fx = foldx_energy(state_x.reshape(-1, q, N), structures)\n",
    "        fx_dna = foldx_energy_with_dna(state_x.reshape(-1, q, N), structures_with_dna, repair = True)\n",
    "        fx_dna_AA = foldx_energy_with_dna(state_x.reshape(-1, q, N), structures_with_dna_AA, repair = True)\n",
    "\n",
    "        TRACK[\"foldx\"].append(fx)\n",
    "        TRACK[\"foldx_dna\"].append(fx_dna)\n",
    "        TRACK[\"foldx_dna_AA\"].append(fx_dna_AA)\n",
    "        TRACK[\"x\"].append(state_x.clone())\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\"\"{n_mut}/{batch_size*i} [{(100*n_mut)/(batch_size*i):.2f}%] \n",
    "            || Class : {state_p.exp().mean().cpu().item():.3f} \n",
    "            || E = {state_e.mean():.3f} \n",
    "            || Dynamic : {list(state_dynamic.detach().numpy())}\n",
    "            || Diff : {list(state_diff.detach().numpy())}\n",
    "            || Foldx = {fx.mean():.3f} \n",
    "            || Foldx DNA = {fx_dna.mean():.3f} \n",
    "            || Foldx DNA AA = {fx_dna_AA.mean():.3f} \n",
    "            || angle = {(angle/(norm_GC*norm_Gphi)).mean():.3f} \n",
    "            || h = {(state_h-h_cas9).pow(2).sum(-1).sqrt().mean():.3f}\"\"\")  \n",
    "    return state_x, state_h, state_xs\n",
    "\n",
    "def display_dynamic(TRACK, phi, n = 8):\n",
    "    pphi1, pphi2, pphi3 = phi\n",
    "    idx = list(range(n))\n",
    "    plt.figure(figsize =(20,5))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi1-0.05,pphi1-0.05], c=\"black\")\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi1+0.05,pphi1+0.05], c=\"black\")\n",
    "    for y in torch.cat(TRACK['E(log P(x))'],-1)[idx]:\n",
    "        plt.plot(y)\n",
    "    plt.title('log P(x)')\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi2-0.1,pphi2-0.1], c=\"black\")\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi2+0.1,pphi2+0.1], c=\"black\")\n",
    "\n",
    "    for y in torch.cat(TRACK['Sim'],-1)[idx]:\n",
    "        plt.plot(y)\n",
    "    plt.title('Hamming Similarity')\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi3-0.05,pphi3-0.05], c=\"black\")\n",
    "    plt.plot([0,len(TRACK['E(log P(x))'])],[pphi3+0.05,pphi3+0.05], c=\"black\")\n",
    "    for y in torch.cat(TRACK['SQA'][1:],-1)[idx]:\n",
    "        plt.plot(y)\n",
    "    plt.title('SQA')\n",
    "\n",
    "    plt.subplot(144)\n",
    "    for y in torch.stack(TRACK['C'],-1)[idx]:\n",
    "        plt.plot(y)\n",
    "    plt.title('Classifier')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def find_closest_sequence(x):\n",
    "    x = x.view(len(x), 21, -1)\n",
    "    distance = (x[:,:,nnz_idx].argmax(-2)[:,None] == existing_sequences[:,:,nnz_idx].argmax(-2)[None]).int().float().mean(-1).max(1)[0]\n",
    "    return distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "914.017px",
    "left": "1557px",
    "right": "20px",
    "top": "195px",
    "width": "281.333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
