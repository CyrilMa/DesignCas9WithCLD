{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, warnings\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from torchpgm.model import *\n",
    "from torchpgm.layers import *\n",
    "\n",
    "from cld.postprocessing import *\n",
    "from cld.criterion import *\n",
    "from cld.walker import *\n",
    "\n",
    "from utils import *\n",
    "from config import *\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d974b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "folder = f\"{DATA}/vink\"\n",
    "Nh, Npam = 200, 5\n",
    "best_epoch = 90\n",
    "q_pi, N_pi = 21, 736\n",
    "model_full_name = f\"rbmssl_pid_h{Nh}_npam{Npam}_gamma5.306595410288844\"\n",
    "\n",
    "\n",
    "def lit_to_pam(s):\n",
    "    pam = []\n",
    "    s += \"N\" * max(0, (Npam - len(s)))\n",
    "    for x in s:\n",
    "        pam += NAd_idx[x]\n",
    "    return torch.tensor(pam).float()[None].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1384d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_gammas = sorted(gammas)[260:542]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0ab97",
   "metadata": {},
   "source": [
    "## Demo of the Constrained Langevin Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3405aa4455ae80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ec797",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = OneHotLayer(None, N=N_pi, q=q_pi, name=\"pi\")\n",
    "h = GaussianLayer(N=Nh, name=\"hidden\")\n",
    "classifier = PAM_classifier(Nh, Npam * 4)\n",
    "E = [(pi.name, h.name)]\n",
    "E.sort()\n",
    "\n",
    "model_rbm = PI_RBM_SSL(classifier, layers={pi.name: pi, h.name: h}, edges=E, name=model_full_name)\n",
    "model_rbm = model_rbm.to(device)\n",
    "model_rbm.load(f\"{folder}/weights/{model_full_name}_{best_epoch}.h5\")\n",
    "model_rbm.eval()\n",
    "model_rbm = model_rbm.to(\"cpu\")\n",
    "model_rbm.ais()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cas9 = torch.load(f\"{DATA}/x_cas9.pt\")\n",
    "zero_idx = torch.load(f\"{DATA}/zero_idx.pt\")\n",
    "kept_idx = list(range(736))\n",
    "target = lit_to_pam(\"NGG\")\n",
    "x_cas9.view(-1,21).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then define the constraints and the objective of the walk and set up the walker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d56a10288c0b21d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "    \n",
    "e = (e0-0.01, e0+0.01)\n",
    "s = (30, 35)\n",
    "T = 0.1*torch.ones(1,1,len(kept_idx))\n",
    "\n",
    "objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "constraints = [\n",
    "            SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0, s[0], 0, s[1])),\n",
    "            RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0, e[0], e0, e[1])),\n",
    "]\n",
    "weight_constraints = [10,1000]\n",
    "\n",
    "walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=.1, n=1, a=1,\n",
    "        c=1e-2, eps=1, target=target.cpu(), T=T, weight_constraints = weight_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We plot some walks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0234acee5f1ad8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004327a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "e_plage = [(e0-0.01, e0+0.01), (e0-0.03, e0-0.02)]    \n",
    "sim_plage = [(30, 35),(50, 55)]\n",
    "x = []\n",
    "TRACKS = []\n",
    "for s, e in zip(sim_plage,e_plage):\n",
    "    objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "    constraints = [\n",
    "                SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "    ]\n",
    "    weight_constraints = [10,1000]\n",
    "\n",
    "    walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=.1, n=1, a=1,\n",
    "            c=1e-2, eps=1, target=target.cpu(), T=T, weight_constraints = weight_constraints)\n",
    "\n",
    "    x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "    e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "    for e_ in e.T[:10]:\n",
    "        plt.plot(e_)\n",
    "    plt.show()\n",
    "    sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "    for sim_ in sim.T[:10]:\n",
    "        plt.plot(sim_)\n",
    "    plt.show()\n",
    "    TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8b0b5",
   "metadata": {},
   "source": [
    "## Generative capacities given $\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We take a look at different values of $\\gamma$ and plot the generated sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4ff61e72d460be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81beab9",
   "metadata": {
    "code_folding": [
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_plage = [(5*i,5*i+5) for i in range(2,10)]\n",
    "for gamma in selected_gammas:\n",
    "    x = []\n",
    "    TRACKS = []\n",
    "    model_full_name = f\"rbmssl_pid_h{Nh}_npam{Npam}_gamma{gamma}\"\n",
    "\n",
    "    model_rbm = PI_RBM_SSL(classifier, layers= {pi.name: pi, h.name: h}, edges=E, name = model_full_name)\n",
    "    model_rbm = model_rbm.to(device)\n",
    "    model_rbm.load(f\"{folder}/weights/{model_full_name}_{best_epoch}.h5\")\n",
    "    model_rbm.eval()\n",
    "    model_rbm.ais()\n",
    "    model_rbm = model_rbm.to(\"cpu\")\n",
    "    model_rbm.Z = model_rbm.Z.cpu()\n",
    "    edge = model_rbm.edges[\"pi -> hidden\"]\n",
    "    \n",
    "    idx0 = 0\n",
    "    idx = (idx0*torch.ones(512).int()).to(device)\n",
    "\n",
    "    x__ = torch.cat([x_cas9.view(21, -1).clone()[None] for i in idx],0)\n",
    "\n",
    "    x_cas9 = torch.clone(x__[0].view(-1))\n",
    "    h_cas9 = edge(x_cas9[None], False)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "    e_plage = [(e0-0.02, e0+0.02)]\n",
    "\n",
    "    for s, e in product(sim_plage,e_plage):\n",
    "        T = 0.1*torch.ones(1,1,len(kept_idx))\n",
    "        objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "        constraints = [\n",
    "                    SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                    RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "        ]\n",
    "        \n",
    "        walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=1, n=1, a=1,\n",
    "                c=1e-2, eps=1, target=target.cpu(), T=T)\n",
    "\n",
    "        x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "        e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "        sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "        TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))\n",
    "    torch.save((x,TRACKS), f\"{folder}/tracks/tracks_{gamma}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7640a0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for (track_e, track_s), (s, e) in zip(TRACKS,product(sim_plage,e_plage)):\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.subplot(121)\n",
    "    print(e,s)\n",
    "    for e_ in track_e[:5]:\n",
    "        plt.plot(-e_)\n",
    "    plt.plot([0,100],[.15,-e[0]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[0],-e[0]],color=\"black\")\n",
    "    plt.plot([0,100],[.15,-e[1]],color=\"black\")\n",
    "    plt.plot([100,200],[-e[1],-e[1]],color=\"black\")\n",
    "    plt.ylabel(\"E_RBM\")\n",
    "    plt.xlabel(\"Step\")\n",
    "\n",
    "    #plt.show()\n",
    "    plt.subplot(122)\n",
    "    for sim_ in track_s[:5]:\n",
    "        plt.plot(sim_)\n",
    "    plt.plot([0,100],[0,s[0]],color=\"black\")\n",
    "    plt.plot([100,200],[s[0],s[0]],color=\"black\")\n",
    "    plt.plot([0,100],[0,s[1]],color=\"black\")\n",
    "    plt.plot([100,200],[s[1],s[1]],color=\"black\")\n",
    "    \n",
    "    plt.ylabel(\"Distance to SpyCas9\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ccc15",
   "metadata": {},
   "source": [
    "## Experimentally tested data and generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{DATA}/ML-designed PID.xlsx\")\n",
    "batch = 0\n",
    "X_labelled = []\n",
    "nnz_idx = [i for i in range(736) if i not in zero_idx]\n",
    "for seq in df.seq[df.batch>=batch]:\n",
    "    seq_onehot = torch.tensor(to_onehot([AA_IDS[x__]+1 if x__ in AA else 0 for x__ in seq],(None,21)).T)\n",
    "    x_ = torch.zeros(21,736)\n",
    "    x_[0] = 1\n",
    "    x_[0, nnz_idx] = 0\n",
    "    x_[:,nnz_idx] = seq_onehot.float()\n",
    "    X_labelled.append(x_)\n",
    "X_labelled = torch.stack(X_labelled,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7700c7842960eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    e0 = (model_rbm({\"pi\":x_cas9[None]})/736 - model_rbm.Z)[0].item()\n",
    "e_plage = [(e0-0.01-0.02*i, e0+0.01-0.02*i) for i in range(6)]    \n",
    "sim_plage = [(10+5*i, 10+5*i+5) for i in range(10)]\n",
    "x = []\n",
    "TRACKS = []\n",
    "for s, e in product(sim_plage,e_plage):\n",
    "    objective = RbmCriterion(model_rbm, postprocessing=ConstantPostprocessor(0))\n",
    "    constraints = [\n",
    "                SimCriterion(x_cas9, list(range(736)), postprocessing = LinearPostprocessor(100, 0,s[0],0,s[1])),\n",
    "                RbmCriterion(model_rbm, postprocessing = LinearPostprocessor(100, e0 ,e[0],e0,e[1])),\n",
    "    ]\n",
    "    weight_constraints = [10,1000]\n",
    "\n",
    "    walker = Walker(x_cas9.view(21, -1).clone(), model_rbm, objective, constraints, zero_idx, gamma=.1, n=1, a=1,\n",
    "            c=1e-2, eps=1, target=target.cpu(), T=T, weight_constraints = weight_constraints)\n",
    "\n",
    "    x.append(walker.run(16, n_epochs = 200, verbose=False))\n",
    "    e = np.concatenate([track[\"e\"][None] for track in walker.TRACKS])\n",
    "    plt.show()\n",
    "    sim = np.concatenate([track[\"abs_diff\"][None] for track in walker.TRACKS])\n",
    "    plt.show()\n",
    "    TRACKS.append((deepcopy(e.T[:10]), deepcopy(sim.T[:10])))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a82f7cca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.cat(x,0).reshape(-1, 21, 736).argmax(1).numpy()\n",
    "aligned_seqs = []\n",
    "unaligned_seqs = []\n",
    "for x_ in xs:\n",
    "    aligned_seqs.append(\"\".join([AA[x__-1] if x__ > 0 else \"-\" for x__ in x_]))\n",
    "    unaligned_seqs.append(\"\".join([AA[x__-1] for x__ in x_ if x__ > 0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "914.017px",
    "left": "1557px",
    "right": "20px",
    "top": "195px",
    "width": "281.333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
